{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# ■ [쉬움주의] 주식 데이터 LSTM 신경망에 넣고 학습시키기\n",
    "# https://www.sedaily.com/NewsView/1ODENF0IMJ\n",
    "# 참고 블러그 : https://kgptalkie.com/google-stock-price-prediction-using-rnn-lstm/\n",
    "# 참고 영상:  https://www.youtube.com/watch?v=arydWPLDnEc&t=2202s\n",
    "\n",
    "# 1. 주가 데이터를 로드 합니다.\n",
    "data = pd.read_csv(\"d:goog.csv\")\n",
    "print(data.tail())\n",
    "print(data.shape)\n",
    "\n",
    "# 2. 훈련데이터와 테스트 데이터를 나눕니다.\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "split_date = datetime.datetime(2009, 1, 1)\n",
    "training_data = data[data['Date'] < split_date].copy()\n",
    "test_data = data[data['Date'] >= split_date].copy()\n",
    "\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "print(training_data)\n",
    "print(test_data)\n",
    "\n",
    "# 3. 예측을 위해 필요한 데이터만 남겨둡니다.\n",
    "training_data = training_data.drop(['Sym', 'Date', 'Adj Close'], axis=1)\n",
    "training_data.head()\n",
    "\n",
    "# 4. 정규화 합니다.\n",
    "scaler = MinMaxScaler()\n",
    "training_data = scaler.fit_transform(training_data)\n",
    "print(training_data.shape)  # (941, 5)\n",
    "\n",
    "# %%\n",
    "# 5.\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, training_data.shape[0]):\n",
    "    x_train.append(training_data[i-60:i])\n",
    "    y_train.append(training_data[i, 0])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "# %%\n",
    "\n",
    "# 6. 위의 코드를 이해하기 위한 코드\n",
    "\n",
    "test_arr = np.arange(4705).reshape(941, 5)\n",
    "print(test_arr)\n",
    "\n",
    "\n",
    "x_train2 = []\n",
    "y_train2 = []\n",
    "\n",
    "for i in range(60, test_arr.shape[0]):\n",
    "    x_train2.append(test_arr[i-60:i])\n",
    "    y_train2.append(test_arr[i, 0])\n",
    "\n",
    "for i, j in zip(x_train2, y_train2):\n",
    "    print(i, '|', j)\n",
    "\n",
    "# %% # 7. 훈련 데이터와 라벨을 numpy array 로 변환합니다.\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# %%  8. 신경망 모델을 생성합니다.\n",
    "\n",
    "\n",
    "regression = Sequential()\n",
    "regression.add(LSTM(units=50, activation=\"relu\",\n",
    "                    return_sequences=True, input_shape=(x_train.shape[1], 5)))\n",
    "regression.add(Dropout(0.2))\n",
    "\n",
    "regression.add(LSTM(units=60, activation=\"relu\", return_sequences=True))\n",
    "regression.add(Dropout(0.3))\n",
    "\n",
    "regression.add(LSTM(units=80, activation=\"relu\", return_sequences=True))\n",
    "regression.add(Dropout(0.4))\n",
    "\n",
    "regression.add(LSTM(units=120, activation=\"relu\"))\n",
    "regression.add(Dropout(0.5))\n",
    "\n",
    "regression.add(Dense(units=1))\n",
    "\n",
    "regression.summary()\n",
    "\n",
    "# %% 9. 시각화 해봅니다.\n",
    "\n",
    "# activate keras_study\n",
    "\n",
    "# conda uninstall pydot\n",
    "# conda uninstall pydotplus\n",
    "# conda uninstall graphviz\n",
    "\n",
    "# conda install pydot\n",
    "# conda install pydotplus\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    regression, 'multi_input_and_output_model.png', show_shapes=True)\n",
    "\n",
    "# %% 10. 학습 시킵니다.\n",
    "\n",
    "regression.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "regression.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# %%\n",
    "\n",
    "# 11. 다시  훈련데이터와 테스트 데이터를 원래데로 나눠 불러옵니다.\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "split_date = datetime.datetime(2009, 1, 1)\n",
    "training_data = data[data['Date'] < split_date].copy()\n",
    "test_data = data[data['Date'] >= split_date].copy()\n",
    "\n",
    "print(training_data.head())\n",
    "\n",
    "past_60_days = training_data.tail(60)\n",
    "\n",
    "print(past_60_days)\n",
    "\n",
    "# %%\n",
    "df = past_60_days.append(test_data, ignore_index=True)\n",
    "df = df.drop(['Sym', 'Date', 'Adj Close'], axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "testing_data = scaler.fit_transform(df)\n",
    "print(testing_data.shape)\n",
    "\n",
    "# %%\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(60, training_data.shape[0]):\n",
    "    x_test.append(testing_data[i-60:i])\n",
    "    y_test.append(testing_data[i, 0])\n",
    "\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# %%\n",
    "\n",
    "y_pred = regression.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "# %%\n",
    "\n",
    "print(scaler.scale_)\n",
    "\n",
    "# %%\n",
    "\n",
    "scale = 1/8.18605127e-04\n",
    "print(scale)\n",
    "\n",
    "# %%\n",
    "\n",
    "y_pred = y_pred*scale\n",
    "y_test = y_test*scale\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "# %%\n",
    "\n",
    "# Visualising the results\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test, color='red', label='Real Google Stock Price')\n",
    "plt.plot(y_pred, color='blue', label='Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# https://www.sedaily.com/NewsView/1ODENF0IMJ\n",
    "\n",
    "# 참고 블러그 : https://kgptalkie.com/google-stock-price-prediction-using-rnn-lstm/\n",
    "\n",
    "# 참고 영상:  https://www.youtube.com/watch?v=arydWPLDnEc&t=2202s\n",
    "\n",
    "# 1. 주가 데이터를 로드 합니다.\n",
    "data = pd.read_csv(\"d:\\\\goog.csv\")\n",
    "print(data.tail())\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "# 2. 훈련데이터와 테스트 데이터를 나눕니다.\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "split_date = datetime.datetime(2009, 1, 1)\n",
    "training_data = data[data['Date'] < split_date].copy()\n",
    "test_data = data[data['Date'] >= split_date].copy()\n",
    "\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "print(training_data)\n",
    "print(test_data)\n",
    "\n",
    "# 3. 예측을 위해 필요한 데이터만 남겨둡니다.\n",
    "training_data = training_data.drop(['Sym', 'Date', 'Adj Close'], axis=1)\n",
    "training_data.head()\n",
    "\n",
    "# 4. 정규화 합니다.\n",
    "scaler = MinMaxScaler()\n",
    "training_data = scaler.fit_transform(training_data)\n",
    "print(training_data.shape)  # (941, 5)\n",
    "\n",
    "# %%\n",
    "# 5.\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, training_data.shape[0]):\n",
    "    x_train.append(training_data[i-60:i])\n",
    "    y_train.append(training_data[i, 0])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "# %%\n",
    "\n",
    "# 6. 위의 코드를 이해하기 위한 코드\n",
    "\n",
    "test_arr = np.arange(4705).reshape(941, 5)\n",
    "print(test_arr)\n",
    "\n",
    "\n",
    "x_train2 = []\n",
    "y_train2 = []\n",
    "\n",
    "for i in range(60, test_arr.shape[0]):\n",
    "    x_train2.append(test_arr[i-60:i])\n",
    "    y_train2.append(test_arr[i, 0])\n",
    "\n",
    "for i, j in zip(x_train2, y_train2):\n",
    "    print(i, '|', j)\n",
    "\n",
    "# %% # 7. 훈련 데이터와 라벨을 numpy array 로 변환합니다.\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# %%  8. 신경망 모델을 생성합니다.\n",
    "\n",
    "\n",
    "regression = Sequential()\n",
    "regression.add(LSTM(units=50, activation=\"relu\",\n",
    "                    return_sequences=True, input_shape=(x_train.shape[1], 5)))\n",
    "regression.add(Dropout(0.2))\n",
    "\n",
    "regression.add(LSTM(units=60, activation=\"relu\", return_sequences=True))\n",
    "regression.add(Dropout(0.3))\n",
    "\n",
    "regression.add(LSTM(units=80, activation=\"relu\", return_sequences=True))\n",
    "regression.add(Dropout(0.4))\n",
    "\n",
    "regression.add(LSTM(units=120, activation=\"relu\"))\n",
    "regression.add(Dropout(0.5))\n",
    "\n",
    "regression.add(Dense(units=1))\n",
    "\n",
    "regression.summary()\n",
    "\n",
    "# %% 9. 시각화 해봅니다.\n",
    "\n",
    "# activate keras_study\n",
    "\n",
    "# conda uninstall pydot\n",
    "# conda uninstall pydotplus\n",
    "# conda uninstall graphviz\n",
    "\n",
    "# conda install pydot\n",
    "# conda install pydotplus\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    regression, 'multi_input_and_output_model.png', show_shapes=True)\n",
    "\n",
    "# %% 10. 학습 시킵니다.\n",
    "\n",
    "regression.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "regression.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# 11. 다시  훈련데이터와 테스트 데이터를 원래데로 나눠 불러옵니다.\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "split_date = datetime.datetime(2009, 1, 1)\n",
    "training_data = data[data['Date'] < split_date].copy()\n",
    "test_data = data[data['Date'] >= split_date].copy()\n",
    "\n",
    "print(training_data.head())\n",
    "\n",
    "past_60_days = training_data.tail(60)\n",
    "\n",
    "print(past_60_days)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "df = past_60_days.append(test_data, ignore_index=True)\n",
    "df = df.drop(['Sym', 'Date', 'Adj Close'], axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "testing_data = scaler.fit_transform(df)\n",
    "print(testing_data.shape)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(60, testing_data.shape[0]):\n",
    "    x_test.append(testing_data[i-60:i])\n",
    "    y_test.append(testing_data[i, 0])\n",
    "\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# %%\n",
    "\n",
    "y_pred = regression.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "# %%\n",
    "\n",
    "print(scaler.scale_)\n",
    "\n",
    "# %%\n",
    "\n",
    "scale = 1/8.18605127e-04\n",
    "print(scale)\n",
    "\n",
    "# %%\n",
    "\n",
    "y_pred = y_pred*scale\n",
    "y_test = y_test*scale\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "# %%\n",
    "\n",
    "# Visualising the results\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test, color='red', label='Real Google Stock Price')\n",
    "plt.plot(y_pred, color='blue', label='Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
