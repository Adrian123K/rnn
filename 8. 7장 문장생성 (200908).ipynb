{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>■ 복습</b>\n",
    "    컴퓨터에게 사람의 말(자연어)을 이해시키기 위해서\n",
    "        비교. CNN: 컴퓨터에게 이미지를 이해시키기 위해서\n",
    "    \n",
    "    2장. 개선된 통계기법 -> 단어의 분산표현 생성(밀집벡터) -> 단어와 단어 사이의 유사성\n",
    "    3장. CBOW 신경망을 이용해서 문장을 학습 시킴 -> 단어의 분산 표현 생성(가중치)\n",
    "    4장. CBOW 신경망에 큰 말뭉치가 입력될 수 있도록 개선\n",
    "        CBOW 신경망의 문제점\n",
    "            1. 말뭉치가 크면 메모리 사용량이 많다\n",
    "            2. 성능이 느림\n",
    "            \n",
    "    5장. RNN 신경망 -> 기억하는 신경망\n",
    "        실습\n",
    "            작은 말뭉치                  --------> RNN 신경망에 입력하고 학습\n",
    "            큰 말뭉치(스티브잡스 연설문)\n",
    "                                  문장을 one hot 표현으로 변경\n",
    "        RNN 신경망의 문제점(한계점)\n",
    "            장기기억 취약\n",
    "            기울기 소실 / 폭발\n",
    "            \n",
    "    6장. LSTM 신경망\n",
    "        RNN과 LSTM 신경망의 차이가 무엇\n",
    "            기억셀 존재\n",
    "            게이트를 추가한 RNN LSTM\n",
    "                forget\n",
    "                input\n",
    "                output\n",
    "                새로운 기억\n",
    "        기울기 소실 문제의 원인 : tanh 함수 -> relu함수\n",
    "        기울기 폭발 문제의 원인 : matmul 연산 -> 게이트 이용해서 크기 조정\n",
    "        LSTM 실습\n",
    "            1. 긍정단어/부정단어를 컴퓨터가 인식할 수 있는지\n",
    "            2. 주가예측을 LSTM 신경망으로 구현\n",
    "            \n",
    "    지금까지 배운 내용으로 생활에 필요한 것을 구현한다면\n",
    "        주가예측 또는 시계열 데이터 분석\n",
    "        \n",
    "    책을 공부하는 방법\n",
    "        RNN 원리를 책의 이론으로 배우고 실습은 keras로 구현\n",
    "    \n",
    "    7장. RNN을 사용해서 문장 생성 : 기사작성, 소설을 쓰는 AI 생성, 번역하는 신경망\n",
    "        실습\n",
    "            1. 영어 문장 생성\n",
    "            2. 덧셈을 하는 신경망 구현\n",
    "    8장. 어텐션 : 인공지능에게 질문을 하면 대답을 하는 것을 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 1. 7장의 큰 그림\n",
    "    이번 7장은 6장에서 다룬 RNN 을 사용한 언어 모델을 쌀째 손질하여, 문장을 생성하는 기능을 구현합니다.\n",
    "    그리고  seq2seq 에게 간단한 덧셈 문제를 학습시켜 구현합니다. seq2seq 는 encoder 와 decoder 를 연결한 모델로, 결국 2개의 RNN 을 조합한 단순한 구조입니다. \n",
    "    하지만 그 단순함에도 불구하고 seq2seq 는 매우 큰 가능성을 지니고 있어서 다양한 에플리케이션에 적용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 2. seq2seq 란 무엇인가요 ?\n",
    "    seqeunce to sequence (시계열에서 시계열)를 뜻하는 말로 한 시계열 데이터를 다른 시계열 데이터로 변환하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 3. seq2seq  구현은 어떻게 하나요 ? \n",
    "    RNN 2개를 연결하는 아주 간단한 방법으로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 4. seq2seq  는 어디에 응용이 되나요 ?\n",
    "    번역, 챗봇, 뉴스기사 자동 생성, 음성 인식 등에 다양하게 응용되어진다\n",
    "                  ↓ \n",
    "             문장 자동 생성(7장)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 5. 5장에서 배웠던 RNN 신경망의 구조는 어떻게 되나요?\n",
    "    You say goodbye and I say hello. 라는 말뭉치가 들어오면 특정 단어가 주어졌을 때 다음으로 나올 확률이 가장 높은 단어가 무엇인지를 예측하는 구조. \n",
    "    확률이 높은 단어는 선택되기 쉽고 확률이 낮은 단어는 선택되게 어려워지게끔 가중치가 생성되는 구조\n",
    "\n",
    "![fig](http://cfile265.uf.daum.net/image/993A34455F543E9F1EDD39)\n",
    "![fig2](http://cfile261.uf.daum.net/image/9943D5495F5440301FF6C8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 6. 그런데 다르게 테스트를 하기 위해서 책에서 결정적이란 용어와 확률적이란 용어를 설명하면서 저자는 결정적인 방법으로 다음 단어를 선택하지 않고 확률적 방법으로 선택하겠다고 하는데 두 용어의 차이가 무엇입니까?\n",
    "    결정적 : 결과가 예측 가능한 것. 기존에 배웠던 것처럼 특정 단어가 주어졌을 때 다음 단어를 예측 가능 확률이 가장 높은 단어를 선택하도록 하는 것\n",
    "    확률적 : 결과가 확률에 따라 정해지는 것. 선택되는 단어는 실행할 때 마다 달라진다.\n",
    "![fig](http://cfile281.uf.daum.net/image/99E3BC355F5442D620D53C)\n",
    "\n",
    "    you say goodbye and i say hello. 라는 문장을 그대도 다 넣는게 아니라 \n",
    "    I 다음에 나올 확률이 높은 say 를 그 다음 입력 단어로 넣고 say 를 입력한 후 다음 단어로 확률이 높은 단어가 hello 이므로 \n",
    "    hello 가 다음 단어로 입력되어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 7. 위와 같이 학습하면 어떤 효과가 있습니까 ?\n",
    "    이렇게 생성된 문장은 훈련 데이터에 존재하지 않는 말. 말 그대로 새로 생성된 문장\n",
    "    언어 모델은 훈련 데이터를 암기한 것이 아니라 훈련 데이터에서 사용된 단어의 패턴을 학습한 것이기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ▩ 8. 문장 자동 생성을 영어 문장 자동 생성으로 테스트 해봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T02:23:57.930614Z",
     "start_time": "2020-09-08T02:23:57.908610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "929589\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from dataset import ptb\n",
    "\"\"\"\n",
    "929_000개의 학습 단어, 73_000개의 validation 단어, 82_000개의 테스트 단어로 구성\n",
    "예: 일기예보 기사를 자동으로 쓰는 AI를 만들고 싶다면 일기예보 기사의 용어(단어)가 들어있는 데이터 셋을 import 해야한다.\n",
    "\"\"\"\n",
    "from ch07.rnnlm_gen import RnnlmGen\n",
    "\"\"\"\n",
    "훈련 데이터의 문장을 암기하는 게 아니라 사용된 단어의 정렬 패턴을 학습하게 한 클래스\n",
    "You say goodbye and I say hello.\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "print(vocab_size) # 10000\n",
    "print(corpus_size) # 929589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T02:14:32.824716Z",
     "start_time": "2020-09-08T02:14:32.597673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 'll take any transformed.\n",
      " once hollywood 's sense is the table in the installed and streak the big board failure in a parental case of fcc lane in five years against mr. roman.\n",
      " upgrade says mr. gorbachev nor blacks and mr. white to veto a oliver gulf a book again.\n",
      " the attack is expected to restrict mr. provinces 's team generation because of making internal material would be pushed and warned between its racketeering changes school.\n",
      " mr. green is only a finnish investor he will use l.a. oliver robinson 's president.\n",
      " material for the\n"
     ]
    }
   ],
   "source": [
    "model = RnnlmGen()\n",
    "model.load_params('ch06/Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word] # you의 단어 id를 추출\n",
    "skip_words = ['N', '<unk>', '$'] # 샘플링 하지 않을 단어를 지정\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
