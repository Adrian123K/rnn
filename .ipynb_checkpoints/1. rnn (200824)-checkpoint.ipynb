{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※ 딥러닝_CNN_NCS_노트정리_문제168_.pdf 다음주 목요일까지 제출\n",
    "\n",
    "## <b>■ CNN으로 할 수 있는 일</b>\n",
    "    1. 불량품 선별을 인공지능이 자동화\n",
    "    2. 영상의학과에서 환자의 CT, MRI 사진을 인공지능이 판독\n",
    "    3. 영상에서 마스크 쓴 사람과 안 쓴 사람을 분류\n",
    "    4. 기타\n",
    "    \n",
    "    CNN 복습\n",
    "        1. 밑바닥 딥러닝 1권\n",
    "        2. Tensorflow 1.x, 1.x+keras, \n",
    "           Tensorflow 2.x\n",
    "           \n",
    "    Tensorflow 2.x의 가장 큰 특징\n",
    "        1. 즉시 실행모드\n",
    "        2. @tf.function으로 파이썬 코드로 gpu를 사용\n",
    "        3. 이미지 증식\n",
    "        4. 가장 최적화된 가중치를 내려받는 기능 (early stop)\n",
    "        5. 전이학습 (미리 만들어 놓은 가중치와 신경망을 가져와서 쓰는 기능)\n",
    "            ex. import VGG16\n",
    "\n",
    "# <b>■ RNN</b>\n",
    "## <b> ■1장. RNN을 배워야하는 이유</b>\n",
    "    1. 번역 신경망 생성\n",
    "        https://github.com/OValery16/Language-Translation-with-deep-learning-\n",
    "    2. 한국어 번역 신경망\n",
    "        https://github.com/haven-jeon/ko_en_neural_machine_translation\n",
    "    3. 주가 예측 \n",
    "        시계열 데이터 분석 가능\n",
    "        https://www.youtube.com/watch?v=pS91rcB3CdM\n",
    "    4. 인공지능과의 대화\n",
    "        https://www.youtube.com/watch?v=m6sWsd_tkAs\n",
    "        https://www.youtube.com/watch?v=NHA69lCd1ZM&feature=youtu.be\n",
    "    \n",
    "## <b>■ 2장. 자연어와 단어의 분산 표현</b>\n",
    "<br><b><h3>문제1. 빈공간의 단어를 채워넣으시오</h></b><br>\n",
    "<b><h4> 2장은 컴퓨터에게 <u>'단어의 의미'</u> 를 이해시키기 위한 기술 내용입니다. <br><br>\n",
    "    이 목적을 달성하기 위해서 <u>'시소러스'</u> 라는 기법을 이용합니다. <br><br>\n",
    "시소러스 기반 기법에서는 단어들의 관련성을 사람이 수작업으로 하나씩 정의 합니다. <br><br>\n",
    "    이 작업은 매우 힘들고 표현력에 한계가 있습니다. 그래서 나온게 <u>'통계기반기법'</u> 인데 통계 기반 기법은 말뭉치로 부터 단어의 의미를 자동으로 추출하고, 그 의미를 벡터로 표현합니다.<br><br>\n",
    "    구체적으로는 단어의 '동시 발생 행렬' 을 만들고, <u>'PPMI 행렬'</u>로 변환한다음, 안정성을 높이기 위해 <u>'특이값 분해(SVD)'</u> 를 이용해 차원을  감소시켜서 각 단어의 분산 표현을 만들어 냅니다. <br><br>\n",
    "    분산 표현에 따르면 의미가 비슷한 단어들의 벡터 공간에서도 서로 가까이 모여 있음을 확인할 수 있습니다.</h></b><br>\n",
    "\n",
    "    ▩ 1. 자연어 처리란 ?     P.78\n",
    "        답: 우리 말을 컴퓨터에게 이해시키기 위한 기술분야\n",
    "\n",
    "    IBM의 슈퍼컴퓨터 ‘IBM왓슨’이 ‘태양의 후예’나 ‘베테랑’ 같은 한국의 인기 드라마·영화 등을 보면서 한국어 공부를 시작했다. \n",
    "    주로 영어 스페인어 등 서구 언어를 습득해온 왓슨이 아시아 언어를 배우는 것은 일본어에 이어 한국어가 두 번째다. \n",
    "    IBM왓슨이 한국어를 습득하면 국내 주요 기업은 물론 정부 및 공공기관 등도 인공지능(AI)을 활용한 고객 응대, 개인화 서비스 등이 가능해질 것으로 예상된다.\n",
    "    데이비드 케니 IBM왓슨 총괄사장(사진)은 21일 서울 여의도 한국IBM 사무실에서 기자 간담회를 열고 “한국은 글로벌 기업이 많이 진출해 있는 중요한 시장이기 때문에 \n",
    "    슈퍼컴퓨터인 왓슨이 한국어를 배우는 것은 필수”라며 “아직은 어린아이가 한글을 배우듯이 한글을 읽고 드라마 등에서 나오는 언어를 계속 반복해 듣고 있는 수준”이라고 설명했다. \n",
    "    왓슨은 인간의 자연어로 묻는 질문에 답할 수 있는 IBM의 인공지능 컴퓨터다. 컴퓨터 언어가 아닌 인간이 쓰는 언어 그대로 인간과 대화하는 것이 가능하다.\n",
    "                                               - 한국경제 IBM 왓슨 '태양의 후예' 보며 한국어 열공 기사중 중에서....\n",
    "\n",
    "    컴퓨터 언어가 아닌 인간이 쓰는 언어 그대로 인간과 대화하는 것이 가능하다.\n",
    "\n",
    "    https://www.youtube.com/watch?v=GV01B5kVsC0\n",
    "\n",
    "\n",
    "    ▩ 2. 자연어 처리가 추구하는 목표는 ?\n",
    "        답: 사람의 말을 컴퓨터가 이해하도록 만들어서 컴퓨터가 우리에게 도움이 되는 일을 수행하게 하는 것\n",
    "\n",
    "    ▩ 3. 시소러스 기법이란 ? \n",
    "        답: 유의어 사전이라는 뜻으로 같은 단어(동의어)들을 다음과 같이 한 그룹으로 분류해두고 단어들간의 관계를 그래프로 표현하여 단어 사이의 연결을 정의\n",
    "    \n",
    "    ▩ 4. 자연어 처리 분야에서 가장 유명한 시소러스는 ?\n",
    "        답: 프린스턴 대학교 WordNet\n",
    "\n",
    "    ▩ 5. 시소러스의 문제점은 ?\n",
    "        답: 사람을 쓰는 비용이 크다.\n",
    "                시소러스는 만드는 데 엄청난 인력 비용이 발생\n",
    "            단어의 의미가 시대적 변화에 대응하기 어렵다.\n",
    "                ex) 창렬하다.\n",
    "            단어의 미묘한 차이를 표현할 수 없다.\n",
    "                ex) 빈티지와 레트로는 같은 의미지만 용법이 다르다.\n",
    "\n",
    "    ▩ 6. 시소러스의 문제점을 피하기 위해서 필요한 기법은 ?\n",
    "        답: 통계 기반 기법과 신경망을 사용한 추론 기반 기법\n",
    "                강아지/고양이 신경망을 만들고 이 신경망에 한번도 보지못한 강아지 사진을 입력하고 맞춰보라고 하면 신경망이 추론을 한다. [0.612, 0.388]\n",
    "\n",
    "    ▩ 7. 말뭉치란 ?\n",
    "        답: 자연어 처리를 염두해두고 수집된 대량의 텍스트 데이터 \n",
    "\n",
    "    ▩ 8. 통계 기반 기법의 목표는 무엇입니까 ?\n",
    "        답: 사람의 지식으로 가득한 말뭉치에서 자동으로, 효율적으로 그 핵심을 추출하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 자연어와 단어의 분산표현 이론 문제_첫번째</b>\n",
    "#### 1. 아래의 스크립트를 수행해보고 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:06:09.988716Z",
     "start_time": "2020-08-24T02:06:09.969728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you say goodbye and i say hello .\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    답:\n",
    "        text의 문장을 소문자로 다 변환한 후 마침표 앞에 공백을 넣은 스크립트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 아래의 스크립트를 수행해보고 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:07:04.215388Z",
     "start_time": "2020-08-24T02:07:04.210390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n"
     ]
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    답:\n",
    "        공백으로 단어들을 분리하여 리스트화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 아래의 스크립트를 수행해보고 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:07:56.721180Z",
     "start_time": "2020-08-24T02:07:56.714189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "\n",
    "print (id_to_word)        \n",
    "print (word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    답:\n",
    "        분리된 단어들을 딕셔너리에 넣으면서 아이디(인덱스) 생성, 아이디를 통해 단어를 value로 하는 딕셔너리 생성\n",
    "            단어:아이디\n",
    "            아이디:단어 \n",
    "        단어의 아이디(인덱스)를 이용하여 단어를 불러오거나 단어를 직접 넣어 아이디(인덱스)를 불러올 수 있도록 생성\n",
    "            text 말뭉치를 자연어 처리하기 위한 전처리 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 아래의 스크립트를 수행해보고 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:09:51.257660Z",
     "start_time": "2020-08-24T02:09:51.249664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n"
     ]
    }
   ],
   "source": [
    "import  numpy as  np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    답:\n",
    "        단어를 인덱스로 생성한 것을 이용하여 문장을 인덱스로 표현\n",
    "        words 리스트에서 단어들을 하나씩 뽑아서 word_to_id에 키로 제공, id를 추출, array로 리스트화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 아래의 스크립트를 수행해보고 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:11:21.372783Z",
     "start_time": "2020-08-24T02:11:21.363788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print (corpus)\n",
    "print (word_to_id)\n",
    "print (id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    답:\n",
    "        위의 일련 과정들을 preprocess 함수를 생성하여 구현\n",
    "        \n",
    "    지금까지의 작업은 말뭉치 전처리 작업\n",
    "    우리의 목표는 말뭉치를 사용해 '단어의 의미'를 추출하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제. 다른 문장을 직접 넣고 똑같이 수행해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:23:53.730059Z",
     "start_time": "2020-08-24T02:23:53.724063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 2 7 8]\n",
      "{'adsp': 0, 'is': 1, 'not': 2, 'a': 3, 'useful': 4, 'certification': 5, 'and': 6, 'easy': 7, '.': 8}\n",
      "{0: 'adsp', 1: 'is', 2: 'not', 3: 'a', 4: 'useful', 5: 'certification', 6: 'and', 7: 'easy', 8: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'Adsp is not a useful certification and not easy.'\n",
    "t_corpus, t_word_to_id, t_id_to_word = preprocess(text)\n",
    "\n",
    "print(t_corpus)\n",
    "print(t_word_to_id)\n",
    "print(t_id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 자연어와 단어의 분산표현 이론 문제_두번째</b>\n",
    "#### 1. 단어의 분산 표현이란?\n",
    "    답: 비색이라는 색깔을 표현할 때 (R,G,B) = (170,33,22)라고 표현하듯\n",
    "        단어의 의미를 벡터로 표현하는 것\n",
    "        ex) [0.21, -0.45, 0.83]\n",
    "\n",
    "![fig2-11](dl2_images/fig2-11(e).png)\n",
    "\n",
    "#### 2. 분포가설이란?\n",
    "    답: 단어의 의미는 주변 단어에 의해 형성된다는 것을 말한다.\n",
    "        그 단어가 사용된 맥락이 그 단어의 의미를 형성한다는 것\n",
    "        ex) 사람이 영어를 독해할 때 모르는 단어가 나올 때 마다 바로 사전을 찾는 것이 아니라 그 주변의 단어들을 보고 그 단어의 뜻을 유추해 내듯\n",
    "            컴퓨터에게도 그렇게 학습을 시킴\n",
    "        ex2) I guzzle beer. we guzzle wine. 이라고 하면 guzzle은 drink와 가까운 의미라는 것일 알 수 있다.\n",
    "        \n",
    "        사람처럼 컴퓨터도 위와 같은 방식으로 학습시킴\n",
    "        \n",
    "#### 3. 맥락이란?\n",
    "    답: 주목하는 단어 주변에 놓인 단어\n",
    "![fig](dl2_images/fig2-3.png)\n",
    "\n",
    "#### 4. 분포가설에 기초해 단어를 벡터로 나타내는 방법 중 통계기법이란?\n",
    "    답: 어떤 단어를 주목했을 때 그 주변에 어떤 단어가 몇 번이나 등장하는지 세어 집계하는 방법\n",
    "![fig](dl2_images/fig2-4.png)\n",
    "![fig](dl2_images/fig2-5.png)\n",
    "\n",
    "#### 5. 동시발생 행렬이란?\n",
    "    답: 문장에서 모든 단어에 대해 동시에 발생하는 단어를 표로 정리한 것\n",
    "![fig](dl2_images/fig2-7.png)    \n",
    "\n",
    "#### 6. 책에서 어떤 문장의 동시 발생 행렬을 자동으로 만들어주는 함수 이름이 무엇입니까?\n",
    "    답: create_co_matrix (p.91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제1. (점심시간 문제) common 폴더안에 util.py에 구현되어 있는 create_co_matrix 함수 코드를 가져와서 아래의 문장의 동시발생행렬을 생성하시오\n",
    "    text = 'you say goodbye and i say hello.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:59:09.177991Z",
     "start_time": "2020-08-24T02:59:09.148010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    \n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "text = 'you say goodbye and i say hello.'\n",
    "vocab_size = 7\n",
    "print(create_co_matrix(corpus,vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 벡터 사이의 유사도를 측정하는 방법은 무엇입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
